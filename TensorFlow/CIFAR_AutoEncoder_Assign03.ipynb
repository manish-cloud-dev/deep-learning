{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assign03.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkFRkMutOxsg",
        "colab_type": "text"
      },
      "source": [
        "## Deep AutoEncoder with keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlLyeejmv87-",
        "colab_type": "text"
      },
      "source": [
        "## CIFAR-10 dataset load/process\n",
        "Q1 Load CIFAR-10 data from Keras Library.\n",
        "\n",
        "a. And Split the same into Train and Test.\n",
        "\n",
        "b. Normalize the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iaqhtImv0KZ",
        "colab_type": "code",
        "outputId": "cd438c81-c60b-4afa-f669-a090f772cbff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#%tensorflow_version 1.x\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPool2D, MaxPooling2D, UpSampling2D, Input\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8dUnbsnnfH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1000\n",
        "num_classes = 10 #  ['Airplane', 'Automobiler', 'Bird', 'Cat', 'Deer', 'Dog','Frog', 'Horse', Ship', 'Truck']\n",
        "epochs = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYW7h3J1xx1k",
        "colab_type": "code",
        "outputId": "dd961a26-39f3-488a-bed8-887211f6878d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "x_train = x_train.astype('float32')/255\n",
        "y_train = y_train.astype('float32')/255\n",
        "#print(x_train[0:3])\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOlmWUPmv755",
        "colab_type": "text"
      },
      "source": [
        "## Q2 Define Encoder/Decoder model\n",
        "######a. Define the Encoder\n",
        "######b. Define the Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60O61ZQRe5MX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_img = Input(shape=(32, 32, 3))\n",
        "\n",
        "#Encoder\n",
        "x = Conv2D(64, (3, 3), padding='same')(input_img)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(16, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "\n",
        "#decoder\n",
        "x = Conv2D(16, (3, 3), padding='same')(encoded)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(3, (3, 3), padding='same')(x)   ## added to match the  dimension\n",
        "x = BatchNormalization()(x)\n",
        "decoded = Activation('sigmoid')(x)\n",
        "\n",
        "model = Model(input_img, decoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9amxongGwytW",
        "colab_type": "text"
      },
      "source": [
        "## Q3 Compile and fit model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74sduhkujuIb",
        "colab_type": "code",
        "outputId": "be81155c-6027-4912-db63-a4041e1e687e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 16, 16, 16)        9232      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 16, 16, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 16, 16, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 16, 16, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2 (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 32, 32, 3)         867       \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 32, 32, 3)         12        \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 32, 32, 3)         0         \n",
            "=================================================================\n",
            "Total params: 19,375\n",
            "Trainable params: 19,113\n",
            "Non-trainable params: 262\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8lRNNAMmzRO",
        "colab_type": "code",
        "outputId": "621f0a98-2efa-4794-98bb-837b9fd9882c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(x_train, x_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, x_test),\n",
        "                    shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 0.6096 - val_loss: -18086.0568\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 6s 118us/step - loss: 0.5814 - val_loss: -18769.6875\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5757 - val_loss: -22884.6344\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5722 - val_loss: -29003.1379\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5698 - val_loss: -35559.0730\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 6s 120us/step - loss: 0.5680 - val_loss: -45609.5520\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 6s 118us/step - loss: 0.5666 - val_loss: -56473.6102\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5655 - val_loss: -67760.7109\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5646 - val_loss: -80538.1922\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5638 - val_loss: -95491.3055\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5632 - val_loss: -104713.7758\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5627 - val_loss: -110193.6891\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5622 - val_loss: -116353.2484\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5618 - val_loss: -124569.1094\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5614 - val_loss: -129104.2508\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5611 - val_loss: -130317.1109\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 6s 120us/step - loss: 0.5607 - val_loss: -130408.3750\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 6s 120us/step - loss: 0.5604 - val_loss: -131459.7039\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5601 - val_loss: -129320.4234\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 6s 120us/step - loss: 0.5599 - val_loss: -132654.4133\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5596 - val_loss: -134446.9219\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 6s 120us/step - loss: 0.5594 - val_loss: -132472.6680\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5591 - val_loss: -136203.7281\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5590 - val_loss: -135616.1484\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5588 - val_loss: -137420.7922\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 6s 120us/step - loss: 0.5586 - val_loss: -135661.0625\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 6s 120us/step - loss: 0.5584 - val_loss: -147887.5109\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5582 - val_loss: -140480.7141\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5581 - val_loss: -146600.7891\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5579 - val_loss: -139456.2313\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5577 - val_loss: -142338.1250\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5576 - val_loss: -135800.5484\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5574 - val_loss: -142584.2453\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5573 - val_loss: -141075.7687\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5572 - val_loss: -145124.8766\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5570 - val_loss: -144519.3297\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5569 - val_loss: -138524.8344\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 6s 120us/step - loss: 0.5568 - val_loss: -139747.6031\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5567 - val_loss: -136738.7109\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5566 - val_loss: -147428.8109\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5565 - val_loss: -145957.4844\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5564 - val_loss: -145768.5516\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5562 - val_loss: -137296.6297\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5562 - val_loss: -144496.0859\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5561 - val_loss: -148823.8297\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 6s 120us/step - loss: 0.5560 - val_loss: -149496.5750\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 6s 120us/step - loss: 0.5559 - val_loss: -145623.0000\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5558 - val_loss: -151723.9937\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5557 - val_loss: -156509.2609\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.5557 - val_loss: -156973.7875\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}